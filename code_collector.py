#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½ä»£ç æ”¶é›†å·¥å…·
æä¾›ä¸€é”®æ‰¹é‡å¯¼å…¥ã€æ™ºèƒ½ç‰‡æ®µæå–ã€è‡ªåŠ¨ç»“æ„å›¾ç”Ÿæˆç­‰åŠŸèƒ½
"""

import os
import json
import sys
import argparse
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Set
from datetime import datetime
import re


class CodeCollector:
    """æ™ºèƒ½ä»£ç æ”¶é›†å™¨"""

    def __init__(self, project_path: str, config: Dict = None):
        """åˆå§‹åŒ–æ”¶é›†å™¨"""
        self.project_path = Path(project_path).resolve()
        self.config = config or {}
        self.collected_files = []
        self.structure_tree = {}

    def batch_import(self, file_paths: List[str]) -> Dict:
        """
        ä¸€é”®æ‰¹é‡å¯¼å…¥å¤šä¸ªæ–‡ä»¶

        å‚æ•°:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„ï¼‰

        è¿”å›:
            {
                "files": [{"path": "...", "content": "...", "language": "...", "lines": 100}, ...],
                "structure": "æ ‘å½¢ç»“æ„å­—ç¬¦ä¸²",
                "stats": {"total_files": 10, "total_lines": 1000, "languages": {...}},
                "skipped_files": [{"path": "...", "reason": "..."}, ...]
            }
        """
        result = {
            "files": [],
            "structure": "",
            "stats": {"total_files": 0, "total_lines": 0, "languages": {}},
            "skipped_files": []
        }

        collected_paths = []
        max_size_kb = self.config.get('max_file_size_kb', 500)

        for file_path in file_paths:
            abs_path = self._resolve_path(file_path)
            if not abs_path.exists() or not abs_path.is_file():
                continue

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size_kb = abs_path.stat().st_size / 1024
            if file_size_kb > max_size_kb:
                result["skipped_files"].append({
                    "path": str(file_path),
                    "reason": f"æ–‡ä»¶è¿‡å¤§ ({file_size_kb:.1f} KB > {max_size_kb} KB)",
                    "size_kb": file_size_kb,
                    "lines": self._count_lines(abs_path)
                })
                continue

            # è¯»å–æ–‡ä»¶å†…å®¹
            content, encoding = self._read_file_safely(abs_path)
            if content is None:
                result["skipped_files"].append({
                    "path": str(file_path),
                    "reason": "ç¼–ç é”™è¯¯ï¼Œæ— æ³•è¯»å–"
                })
                continue

            # è·å–ç›¸å¯¹è·¯å¾„
            try:
                rel_path = abs_path.relative_to(self.project_path)
            except ValueError:
                rel_path = abs_path

            # è¯­è¨€æ£€æµ‹
            language = self._detect_language(abs_path)
            lines = len(content.splitlines())

            result["files"].append({
                "path": str(rel_path),
                "content": content,
                "language": language,
                "lines": lines,
                "size_kb": abs_path.stat().st_size / 1024
            })

            collected_paths.append(rel_path)

            # æ›´æ–°ç»Ÿè®¡
            result["stats"]["total_lines"] += lines
            result["stats"]["languages"][language] = result["stats"]["languages"].get(language, 0) + 1

        result["stats"]["total_files"] = len(result["files"])

        # ç”Ÿæˆç›®å½•ç»“æ„
        result["structure"] = self._generate_tree_structure(collected_paths)

        return result

    def extract_snippets(self, file_path: str, ranges: List[Dict]) -> Dict:
        """
        æ™ºèƒ½ç‰‡æ®µæå–ï¼ˆæ”¯æŒè¡Œå·èŒƒå›´å’Œå‡½æ•°åï¼‰

        å‚æ•°:
            file_path: æ–‡ä»¶è·¯å¾„
            ranges: æå–èŒƒå›´åˆ—è¡¨
                [
                    {"type": "lines", "start": 10, "end": 50},
                    {"type": "function", "name": "calculate_total"},
                    {"type": "class", "name": "UserModel"}
                ]

        è¿”å›:
            {
                "file_path": "...",
                "snippets": [
                    {"type": "lines", "range": "10-50", "content": "...", "lines": 41},
                    {"type": "function", "name": "calculate_total", "content": "...", "lines": 15}
                ],
                "total_lines": 56
            }
        """
        abs_path = self._resolve_path(file_path)
        if not abs_path.exists():
            return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}

        content, _ = self._read_file_safely(abs_path)
        if content is None:
            return {"error": f"æ— æ³•è¯»å–æ–‡ä»¶: {file_path}"}

        lines = content.splitlines()
        result = {
            "file_path": str(file_path),
            "snippets": [],
            "total_lines": 0
        }

        for range_spec in ranges:
            snippet = None

            if range_spec["type"] == "lines":
                # æŒ‰è¡Œå·æå–
                start = range_spec.get("start", 1) - 1  # è½¬æ¢ä¸º 0-based
                end = range_spec.get("end", len(lines))
                snippet_lines = lines[start:end]

                snippet = {
                    "type": "lines",
                    "range": f"{start + 1}-{end}",
                    "content": "\n".join(snippet_lines),
                    "lines": len(snippet_lines)
                }

            elif range_spec["type"] in ["function", "class", "method"]:
                # æŒ‰å‡½æ•°/ç±»åæå–
                name = range_spec.get("name")
                snippet_content, snippet_lines = self._extract_by_name(
                    content,
                    name,
                    range_spec["type"],
                    abs_path.suffix
                )

                if snippet_content:
                    snippet = {
                        "type": range_spec["type"],
                        "name": name,
                        "content": snippet_content,
                        "lines": snippet_lines
                    }

            if snippet:
                result["snippets"].append(snippet)
                result["total_lines"] += snippet["lines"]

        return result

    def generate_markdown(self, data: Dict, user_intent: str = "") -> str:
        """
        ç”Ÿæˆ Markdown æ–‡æ¡£

        å‚æ•°:
            data: batch_import æˆ– extract_snippets è¿”å›çš„æ•°æ®
            user_intent: ç”¨æˆ·æ„å›¾æè¿°

        è¿”å›:
            å®Œæ•´çš„ Markdown å­—ç¬¦ä¸²
        """
        md_parts = []

        # æ ‡é¢˜
        project_name = self.project_path.name
        md_parts.append(f"# Project: {project_name}\n")

        # å…ƒä¿¡æ¯
        md_parts.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        if user_intent:
            md_parts.append(f"**æ”¶é›†ç›®çš„**: {user_intent}\n")

        # é¡¹ç›®ç±»å‹ï¼ˆå¦‚æœæœ‰ï¼‰
        if "detected_project_type" in self.config:
            md_parts.append(f"**é¡¹ç›®ç±»å‹**: {self.config.get('project_type_name', 'æœªçŸ¥')}\n")

        md_parts.append("\n---\n\n")

        # ç›®å½•ç»“æ„
        if "structure" in data and data["structure"]:
            md_parts.append("## ğŸ“ ç›®å½•ç»“æ„\n\n")
            md_parts.append("```text\n")
            md_parts.append(data["structure"])
            md_parts.append("\n```\n\n---\n\n")

        # æ–‡ä»¶å†…å®¹ï¼ˆæ‰¹é‡å¯¼å…¥æ¨¡å¼ï¼‰
        if "files" in data:
            # æ ¸å¿ƒæ–‡ä»¶ä¼˜å…ˆ
            core_files = []
            other_files = []

            for file_info in data["files"]:
                if self._is_core_file(file_info["path"]):
                    core_files.append(file_info)
                else:
                    other_files.append(file_info)

            if core_files:
                md_parts.append("## ğŸ¯ æ ¸å¿ƒæ–‡ä»¶\n\n")
                for file_info in core_files:
                    md_parts.append(self._format_file_section(file_info))

            if other_files:
                md_parts.append("## ğŸ“„ ä»£ç æ–‡ä»¶\n\n")
                for file_info in other_files:
                    md_parts.append(self._format_file_section(file_info))

        # ä»£ç ç‰‡æ®µï¼ˆç‰‡æ®µæå–æ¨¡å¼ï¼‰
        if "snippets" in data:
            md_parts.append(f"## ğŸ“„ ä»£ç ç‰‡æ®µ: {data['file_path']}\n\n")
            for snippet in data["snippets"]:
                md_parts.append(self._format_snippet_section(snippet))

        # ç»Ÿè®¡ä¿¡æ¯
        if "stats" in data:
            md_parts.append("## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯\n\n")
            stats = data["stats"]
            md_parts.append(f"- æ€»æ–‡ä»¶æ•°ï¼š{stats['total_files']}\n")
            md_parts.append(f"- æ€»ä»£ç è¡Œæ•°ï¼š{stats['total_lines']}\n")

            if stats.get("languages"):
                lang_stats = []
                total = sum(stats["languages"].values())
                for lang, count in sorted(stats["languages"].items(), key=lambda x: x[1], reverse=True):
                    pct = (count / total) * 100
                    lang_stats.append(f"{lang} ({pct:.1f}%)")
                md_parts.append(f"- ä¸»è¦è¯­è¨€ï¼š{', '.join(lang_stats)}\n")

        # è·³è¿‡çš„æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
        if "skipped_files" in data and data["skipped_files"]:
            md_parts.append("\n---\n\n")
            md_parts.append("## âš ï¸ è·³è¿‡çš„æ–‡ä»¶\n\n")
            md_parts.append("ä»¥ä¸‹æ–‡ä»¶å› ä½“ç§¯è¿‡å¤§æˆ–ç¼–ç é—®é¢˜æœªèƒ½è‡ªåŠ¨æ”¶é›†ï¼Œ**éœ€è¦ Agent æ‰‹åŠ¨å¤„ç†**ï¼š\n\n")
            for skipped in data["skipped_files"]:
                md_parts.append(f"### {skipped['path']}\n\n")
                md_parts.append(f"- **åŸå› **ï¼š{skipped['reason']}\n")
                if 'size_kb' in skipped:
                    md_parts.append(f"- **æ–‡ä»¶å¤§å°**ï¼š{skipped['size_kb']:.1f} KB\n")
                if 'lines' in skipped and skipped['lines']:
                    md_parts.append(f"- **é¢„ä¼°è¡Œæ•°**ï¼šçº¦ {skipped['lines']} è¡Œ\n")
                md_parts.append(f"- **å»ºè®®**ï¼šä½¿ç”¨ç‰‡æ®µæå–æ¨¡å¼ (--mode snippets) æŒ‡å®šå‡½æ•°/ç±»åæˆ–è¡Œå·èŒƒå›´\n\n")

        # ç”¨æˆ·æ„å›¾æ€»ç»“ï¼ˆæ–‡æœ«ï¼‰
        if user_intent:
            md_parts.append("\n---\n\n")
            md_parts.append("## ğŸ¯ æ”¶é›†ç›®çš„æ€»ç»“\n\n")
            md_parts.append(f"{user_intent}\n\n")
            md_parts.append("**æç¤º**ï¼šä»¥ä¸Šä»£ç å·²æ ¹æ®æ­¤ç›®çš„æ”¶é›†æ•´ç†ï¼Œå¯ç›´æ¥ç”¨äºç›¸å…³åˆ†ææˆ–å¼€å‘ä»»åŠ¡ã€‚\n")

        return "".join(md_parts)

    def _resolve_path(self, path: str) -> Path:
        """è§£æè·¯å¾„ï¼ˆæ”¯æŒç›¸å¯¹å’Œç»å¯¹è·¯å¾„ï¼‰"""
        p = Path(path)
        if p.is_absolute():
            return p
        return self.project_path / p

    def _read_file_safely(self, path: Path) -> Tuple[Optional[str], Optional[str]]:
        """å®‰å…¨è¯»å–æ–‡ä»¶ï¼ˆå°è¯•å¤šç§ç¼–ç ï¼‰"""
        encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']

        for encoding in encodings:
            try:
                with open(path, 'r', encoding=encoding) as f:
                    return f.read(), encoding
            except (UnicodeDecodeError, FileNotFoundError):
                continue

        return None, None

    def _count_lines(self, path: Path) -> Optional[int]:
        """å¿«é€Ÿç»Ÿè®¡æ–‡ä»¶è¡Œæ•°ï¼ˆä¸å®Œæ•´è¯»å–ï¼‰"""
        try:
            with open(path, 'rb') as f:
                return sum(1 for _ in f)
        except:
            return None

    def _detect_language(self, path: Path) -> str:
        """æ£€æµ‹ç¼–ç¨‹è¯­è¨€"""
        ext = path.suffix.lower()
        lang_map = {
            '.py': 'python', '.js': 'javascript', '.ts': 'typescript',
            '.jsx': 'jsx', '.tsx': 'tsx', '.java': 'java',
            '.cpp': 'cpp', '.c': 'c', '.h': 'c', '.hpp': 'cpp',
            '.cs': 'csharp', '.go': 'go', '.rs': 'rust',
            '.rb': 'ruby', '.php': 'php', '.swift': 'swift',
            '.kt': 'kotlin', '.scala': 'scala', '.r': 'r',
            '.m': 'objective-c', '.sql': 'sql', '.sh': 'bash',
            '.yaml': 'yaml', '.yml': 'yaml', '.json': 'json',
            '.xml': 'xml', '.html': 'html', '.css': 'css',
            '.scss': 'scss', '.sass': 'sass', '.md': 'markdown',
            '.vue': 'vue', '.svelte': 'svelte'
        }
        return lang_map.get(ext, 'text')

    def _generate_tree_structure(self, file_paths: List[Path]) -> str:
        """ç”Ÿæˆæ ‘å½¢ç›®å½•ç»“æ„"""
        if not file_paths:
            return ""

        # æ„å»ºæ ‘å½¢ç»“æ„
        tree = {}
        for path in file_paths:
            parts = path.parts
            current = tree
            for part in parts:
                if part not in current:
                    current[part] = {}
                current = current[part]

        # æ¸²æŸ“æ ‘å½¢ç»“æ„
        def render_tree(node: Dict, prefix: str = "", is_last: bool = True) -> List[str]:
            lines = []
            items = sorted(node.items())

            for i, (name, children) in enumerate(items):
                is_last_item = (i == len(items) - 1)

                if prefix == "":
                    lines.append(f"{name}/")
                    lines.extend(render_tree(children, "    ", is_last_item))
                else:
                    connector = "â””â”€â”€ " if is_last_item else "â”œâ”€â”€ "
                    is_file = len(children) == 0
                    display_name = name if is_file else f"{name}/"
                    lines.append(f"{prefix}{connector}{display_name}")

                    if children:
                        extension = "    " if is_last_item else "â”‚   "
                        lines.extend(render_tree(children, prefix + extension, is_last_item))

            return lines

        tree_lines = render_tree(tree)
        return "\n".join(tree_lines)

    def _extract_by_name(self, content: str, name: str, element_type: str, file_ext: str) -> Tuple[Optional[str], int]:
        """æ ¹æ®å‡½æ•°/ç±»åæå–ä»£ç """
        lines = content.splitlines()

        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©æ­£åˆ™æ¨¡å¼
        if file_ext in ['.py']:
            if element_type == 'function':
                pattern = rf'^\s*def\s+{re.escape(name)}\s*\('
            elif element_type == 'class':
                pattern = rf'^\s*class\s+{re.escape(name)}\s*[\(:]'
            else:
                return None, 0
        elif file_ext in ['.js', '.ts', '.jsx', '.tsx']:
            if element_type == 'function':
                pattern = rf'(function\s+{re.escape(name)}\s*\(|const\s+{re.escape(name)}\s*=|\s+{re.escape(name)}\s*\()'
            elif element_type == 'class':
                pattern = rf'class\s+{re.escape(name)}\s*'
            else:
                return None, 0
        elif file_ext in ['.java', '.kt', '.cs']:
            if element_type in ['function', 'method']:
                pattern = rf'\s+{re.escape(name)}\s*\('
            elif element_type == 'class':
                pattern = rf'class\s+{re.escape(name)}\s*'
            else:
                return None, 0
        else:
            # é€šç”¨æ¨¡å¼
            pattern = rf'\b{re.escape(name)}\b'

        # æŸ¥æ‰¾å®šä¹‰è¡Œ
        start_line = None
        for i, line in enumerate(lines):
            if re.search(pattern, line):
                start_line = i
                break

        if start_line is None:
            return None, 0

        # ç¡®å®šç»“æŸè¡Œï¼ˆåŸºäºç¼©è¿›ï¼‰
        base_indent = len(lines[start_line]) - len(lines[start_line].lstrip())
        end_line = start_line + 1

        for i in range(start_line + 1, len(lines)):
            line = lines[i]
            if line.strip() == "":
                continue

            current_indent = len(line) - len(line.lstrip())

            # å¦‚æœç¼©è¿›å›åˆ°åŒçº§æˆ–æ›´å°‘ï¼Œç»“æŸ
            if current_indent <= base_indent and line.strip():
                end_line = i
                break
        else:
            end_line = len(lines)

        snippet_lines = lines[start_line:end_line]
        return "\n".join(snippet_lines), len(snippet_lines)

    def _is_core_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ ¸å¿ƒæ–‡ä»¶"""
        core_files = self.config.get('core_files', [])
        file_name = Path(file_path).name

        # æ£€æŸ¥å®Œæ•´è·¯å¾„æˆ–æ–‡ä»¶å
        return any(
            file_path == core or
            file_name == core or
            file_path.endswith(core)
            for core in core_files
        )

    def _format_file_section(self, file_info: Dict) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶æ®µè½"""
        md = f"### File: {file_info['path']}\n\n"
        md += f"```{file_info['language']}\n"
        md += file_info['content']
        md += "\n```\n\n---\n\n"
        return md

    def _format_snippet_section(self, snippet: Dict) -> str:
        """æ ¼å¼åŒ–ä»£ç ç‰‡æ®µæ®µè½"""
        if snippet['type'] == 'lines':
            md = f"### è¡Œ {snippet['range']}\n\n"
        else:
            md = f"### {snippet['type'].title()}: {snippet['name']}\n\n"

        md += "```\n"
        md += snippet['content']
        md += "\n```\n\n---\n\n"
        return md


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(description='æ™ºèƒ½ä»£ç æ”¶é›†å·¥å…·')
    parser.add_argument('project_path', help='é¡¹ç›®è·¯å¾„')
    parser.add_argument('--mode', choices=['batch', 'snippets'], required=True,
                        help='è¿è¡Œæ¨¡å¼ï¼šbatchï¼ˆæ‰¹é‡å¯¼å…¥ï¼‰æˆ– snippetsï¼ˆç‰‡æ®µæå–ï¼‰')
    parser.add_argument('--files', nargs='+', help='æ–‡ä»¶åˆ—è¡¨ï¼ˆbatch æ¨¡å¼ï¼‰')
    parser.add_argument('--target', help='ç›®æ ‡æ–‡ä»¶ï¼ˆsnippets æ¨¡å¼ï¼‰')
    parser.add_argument('--ranges', help='æå–èŒƒå›´ JSONï¼ˆsnippets æ¨¡å¼ï¼‰')
    parser.add_argument('--intent', help='ç”¨æˆ·æ„å›¾æè¿°')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONï¼‰')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = {}
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r', encoding='utf-8') as f:
            config = json.load(f)

    # åˆ›å»ºæ”¶é›†å™¨
    collector = CodeCollector(args.project_path, config)

    # æ‰§è¡Œæ”¶é›†
    if args.mode == 'batch':
        if not args.files:
            print("é”™è¯¯ï¼šbatch æ¨¡å¼éœ€è¦æŒ‡å®š --files", file=sys.stderr)
            sys.exit(1)

        data = collector.batch_import(args.files)

    elif args.mode == 'snippets':
        if not args.target or not args.ranges:
            print("é”™è¯¯ï¼šsnippets æ¨¡å¼éœ€è¦æŒ‡å®š --target å’Œ --ranges", file=sys.stderr)
            sys.exit(1)

        ranges = json.loads(args.ranges)
        data = collector.extract_snippets(args.target, ranges)

    # ç”Ÿæˆ Markdown
    markdown = collector.generate_markdown(data, args.intent or "")

    # è¾“å‡º
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"âœ… å·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(markdown)


if __name__ == "__main__":
    main()
